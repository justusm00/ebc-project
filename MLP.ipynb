{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to predict missing Flux-data for GÃ¶ttingen forest and the forst bothanical garden.  \n",
    "The approach used is an MLP. Be careful to adjust how many cpu cores u want to use during training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important  imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import fastprogress\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 CPUs available, 4 were assigned\n"
     ]
    }
   ],
   "source": [
    "# Get number of cpus to use for faster parallelized data loading\n",
    "avb_cpus = os.cpu_count()\n",
    "\n",
    "num_cpus = 4\n",
    "\n",
    "print(avb_cpus, 'CPUs available,', num_cpus, 'were assigned' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# UTILITIES ############\n",
    "\n",
    "from modules.util import EBCDataset, grab_data, train_val_test_splitter, data_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# TRAINING FUNCTIONS ###############\n",
    "\n",
    "# Define validation metric\n",
    "def prediction_error(y, y_pred): \n",
    "    #return abs(y - y_pred)\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(dataloader, optimizer, model, master_bar, loss_fn = nn.MSELoss()):\n",
    "    \"\"\"Run one training epoch.\n",
    "\n",
    "    Args:\n",
    "        dataloade: dataloader containing trainingdata\n",
    "        optimizer: Torch optimizer object\n",
    "        model: the model that is trained\n",
    "        loss_fn: the loss function to be used -> nn.MSELoss()\n",
    "        master_bar: Will be iterated over for each\n",
    "            epoch to draw batches and display training progress\n",
    "\n",
    "    Returns:\n",
    "        Mean epoch loss and accuracy\n",
    "    \"\"\"\n",
    "    loss = []\n",
    "    total_prediction_error = 0\n",
    "\n",
    "    for x, y in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
    "        # Reset optimmizers\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # For calculating the prediction error, add the distance between y and y_pred\n",
    "        # to the total error\n",
    "        total_prediction_error += prediction_error(y, y_pred)\n",
    "\n",
    "        # Compute loss\n",
    "        epoch_loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Backward pass\n",
    "        epoch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # For plotting the train loss, save it for each sample\n",
    "        loss.append(epoch_loss.item())\n",
    "\n",
    "    # Return the mean loss and the accuracy of this epoch\n",
    "    return np.mean(loss), total_prediction_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validate(dataloader, model, master_bar, loss_fn=nn.MSELoss()):\n",
    "    \"\"\"Compute loss and total prediction error on validation set.\n",
    "\n",
    "    Args:\n",
    "        dataloader: dataloader containing validation data\n",
    "        model (nn.Module): the model to train\n",
    "        loss_fn: the loss function to be used, defaults to MSELoss\n",
    "        master_bar (fastprogress.master_bar): Will be iterated over to draw \n",
    "            batches and show validation progress\n",
    "\n",
    "    Returns:\n",
    "        Mean loss and total prediction error on validation set\n",
    "    \"\"\"\n",
    "    epoch_loss = []\n",
    "    total_prediction_error = 0  \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
    "            # make a prediction on validation set\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # For calculating the prediction error, add the distance between y and y_pred\n",
    "            # to the total error\n",
    "            total_prediction_error += prediction_error(y, y_pred)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            # For plotting the train loss, save it for each sample\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "    # Return the mean loss, the accuracy and the confusion matrix\n",
    "    return np.mean(epoch_loss), total_prediction_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot(title, label, train_results, val_results, yscale='linear', save_path=None):\n",
    "    \"\"\"Plot learning curves.\n",
    "\n",
    "    Args:\n",
    "        title: Title of plot\n",
    "        label: y-axis label\n",
    "        train_results: Vector containing training results over epochs\n",
    "        val_results: vector containing validation results over epochs\n",
    "        yscale: Defines how the y-axis scales\n",
    "        save_path: Optional path for saving file\n",
    "    \"\"\"\n",
    "    \n",
    "    epochs = np.arange(len(train_results)) + 1\n",
    "    \n",
    "    sns.set(style='ticks')\n",
    "\n",
    "    plt.plot(epochs, train_results, epochs, val_results, linestyle='dashed', marker='o')\n",
    "    legend = ['Train results', 'Validation results']\n",
    "        \n",
    "    plt.legend(legend)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(label)\n",
    "    plt.yscale(yscale)\n",
    "    plt.title(title)\n",
    "    \n",
    "    sns.despine(trim=True, offset=5)\n",
    "    plt.title(title, fontsize=15)\n",
    "    if save_path:\n",
    "        plt.savefig(str(os.path.join( save_path , label+\".png\")), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_training(model, optimizer, num_epochs, train_dataloader, val_dataloader, \n",
    "                 loss_fn=nn.MSELoss(), verbose=False):\n",
    "    \"\"\"Run model training.\n",
    "\n",
    "    Args:\n",
    "        model: The model to be trained\n",
    "        optimizer: The optimizer used during training\n",
    "        loss_fn: Torch loss function for training -> nn.MSELoss()\n",
    "        num_epochs: How many epochs the model is trained for\n",
    "        train_dataloader:  dataloader containing training data\n",
    "        val_dataloader: dataloader containing validation data\n",
    "        verbose: Whether to print information on training progress\n",
    "\n",
    "    Returns:\n",
    "        lists containing  losses and total prediction errors per epoch for training and validation\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    master_bar = fastprogress.master_bar(range(num_epochs))\n",
    "    train_losses, val_losses, train_tpes, val_tpes = [],[],[],[]\n",
    "\n",
    "    for epoch in master_bar:\n",
    "        # Train the model\n",
    "        epoch_train_loss, epoch_train_tpe = train(train_dataloader, optimizer, model, \n",
    "                                                 master_bar, loss_fn)\n",
    "        # Validate the model\n",
    "        epoch_val_loss, epoch_val_tpe = validate(val_dataloader, model, master_bar, loss_fn)\n",
    "\n",
    "        # Save loss and acc for plotting\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        train_tpes.append(epoch_train_tpe)\n",
    "        val_tpes.append(epoch_val_tpe)\n",
    "        \n",
    "        if verbose:\n",
    "            master_bar.write(f'Train loss: {epoch_train_loss:.2f}, val loss: {epoch_val_loss:.2f}, train acc: {epoch_train_tpe:.3f}, val acc {epoch_val_tpe:.3f}')\n",
    "\n",
    "    time_elapsed = np.round(time.time() - start_time, 0).astype(int)\n",
    "    print(f'Finished training after {time_elapsed} seconds.')\n",
    "\n",
    "    plot(\"Loss\", \"Loss\", train_losses, val_losses)\n",
    "    plot(\"TPE\", \"TPE\", train_tpes, val_tpes)\n",
    "\n",
    "    return train_losses, val_losses, train_tpes, val_tpes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models import MLP\n",
    "from params import COLS_METEO, COLS_FLUXES, COLS_FEATURES, COLS_LABELS, PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data and create data loaders\n",
    "# if COLS_METEO and COLS_FLUXES are changed make sure to run the preprocessing pipeline first\n",
    "dataset, num_data, num_labels = grab_data('data/data_merged_without_nans.csv', COLS_FEATURES, COLS_LABELS)\n",
    "\n",
    "trainset, valset, testset = train_val_test_splitter(dataset)\n",
    "\n",
    "\n",
    "# normalize features based on trainset statistics only\n",
    "# trainset_mean = torch.mean(trainset.dataset.dataset.data, dim=0)\n",
    "# trainset_std = torch.std(trainset.dataset.dataset.data, dim=0)\n",
    "\n",
    "# trainset.dataset.dataset.data = (trainset.dataset.dataset.data - trainset_mean) / trainset_std\n",
    "# valset.dataset.dataset.data = (valset.dataset.dataset.data - trainset_mean) / trainset_std\n",
    "# testset.dataset.data = (trainset.dataset.dataset.data - trainset_mean) / trainset_std\n",
    "\n",
    "\n",
    "\n",
    "trainloader, valloader, testloader = data_loaders(trainset, valset, testset, num_cpus=num_cpus, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should one model per location be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      24.00% [12/50 01:08&lt;03:36]\n",
       "    </div>\n",
       "    \n",
       "Train loss: 5857.72, val loss: 5180.55, train acc: 0.000, val acc 0.000<p>Train loss: 5795.84, val loss: 5153.39, train acc: 0.000, val acc 0.000<p>Train loss: 5784.79, val loss: 5233.36, train acc: 0.000, val acc 0.000<p>Train loss: 5793.69, val loss: 5168.33, train acc: 0.000, val acc 0.000<p>Train loss: 5798.02, val loss: 5164.93, train acc: 0.000, val acc 0.000<p>Train loss: 5794.86, val loss: 5184.75, train acc: 0.000, val acc 0.000<p>Train loss: 5791.49, val loss: 5142.98, train acc: 0.000, val acc 0.000<p>Train loss: 5794.45, val loss: 5154.34, train acc: 0.000, val acc 0.000<p>Train loss: 5792.52, val loss: 5140.97, train acc: 0.000, val acc 0.000<p>Train loss: 5792.56, val loss: 5139.04, train acc: 0.000, val acc 0.000<p>Train loss: 5788.83, val loss: 5295.47, train acc: 0.000, val acc 0.000<p>Train loss: 5791.05, val loss: 5161.95, train acc: 0.000, val acc 0.000<p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='333' class='' max='656' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.76% [333/656 00:02&lt;00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = MLP(num_data, num_labels, num_hidden_units=30, num_hidden_layers=4)\n",
    "# Set loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "lr = 10**(-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "train_losses, val_losses, train_tpes, val_tpes = run_training(model, optimizer, num_epochs, trainloader, valloader, \n",
    "                                                              criterion, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model_saves/mlp_1.pth' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
