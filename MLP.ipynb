{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important  imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 CPUs available\n"
     ]
    }
   ],
   "source": [
    "# Get number of cpus to use for faster parallelized data loading\n",
    "num_cpus = os.cpu_count()\n",
    "print(num_cpus, 'CPUs available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset\n",
    "class EBCDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n",
    "\n",
    "\n",
    "\n",
    "# Data loader\n",
    "def grab_data(num_cpus=1):\n",
    "    \"\"\"Loads data from data_dir\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Directory to store data\n",
    "        num_cpus (int, optional): Number of cpus that should be used to \n",
    "            preprocess data. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        Returns datasets as Dataset class for GÃ¶ttingen forest and Bothanic Garden\n",
    "    \"\"\"\n",
    "    # Load the data from 2023 and 2024 into pandas\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    data2023_BoG = pd.read_csv(os.path.join( cwd, 'data_2023/Fluxes_H_LE_CO2/BoG/FBG_fluxes_30min_20230101_20230801.csv' ))\n",
    "    data2023_GoeWa = pd.read_csv(os.path.join( cwd, 'data_2023/Fluxes_H_LE_CO2/GoeWa/GoeW_fluxes_30min_20230101_20230801.csv' ))\n",
    "    data2024_BoG = pd.read_csv(os.path.join( cwd, 'data_2024/EddyCovarianceData/eng/FBG_fluxes_30min_20240401_20240608_eng.csv' ))\n",
    "    data2024_GoeWa = pd.read_csv( os.path.join( cwd, 'data_2024/EddyCovarianceData/eng/GoeW_fluxes_30min_20240401_20240608_eng.csv' ) )\n",
    "\n",
    "    # Select data and labels\n",
    "\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "    # BoG23_set = EBCDataset( , , transform=transform )\n",
    "    # BoG24_set = EBCDataset( , , transform=transform )\n",
    "    # GoeWa23_set = EBCDataset( , , transform=transform )\n",
    "    # GoeWa24_set = EBCDataset( , , transform=transform )\n",
    "\n",
    "    # Bog = torch.utils.data.ConcatDataset( [BoG23_set, BoG24_set] )\n",
    "    # GoeWa = torch.utils.data.ConcatDataset( [GoeWa23_set, GoeWa24_set] )\n",
    "\n",
    "    return BoG, GoeWa\n",
    "\n",
    "\n",
    "\n",
    "# dataset Splitter \n",
    "def train_val_test_splitter(dataset, split_seed=42, test_frac=0.2, val_frac = 0.2):\n",
    "    \"\"\" Splits given dataset into train, val and test datasets\n",
    "\n",
    "    Args:\n",
    "        dataset: the given dataset\n",
    "        split_seed: the seed used for the rng\n",
    "        test_frac: fraction of data used for testing\n",
    "        val_frac_ fraction of training data used for validation\n",
    "    \"\"\"\n",
    "    # Train Test Split\n",
    "    num_test_samples = np.ceil(test_frac * dataset.data.shape[0]).astype(int)\n",
    "    num_train_samples = dataset.data.shape[0] - num_test_samples\n",
    "    trainset, testset = torch.utils.data.random_split(dataset, \n",
    "                                                    (num_train_samples, num_test_samples), \n",
    "                                                    generator=torch.Generator().manual_seed(split_seed))\n",
    "    \n",
    "    # Train Val Split\n",
    "    num_val_samples = np.ceil(val_frac * trainset.data.shape[0]).astype(int)\n",
    "    num_train_samples = trainset.data.shape[0] - num_val_samples\n",
    "    trainset, valset = torch.utils.data.random_split(trainset, \n",
    "                                                    (num_train_samples, num_val_samples), \n",
    "                                                    generator=torch.Generator().manual_seed(split_seed))\n",
    "    \n",
    "    return trainset, valset, testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
